spring:
  port: 8080
  application:
    name: file-processor
  datasource:
    url: jdbc:h2:mem:csvfiledb;DB_CLOSE_DELAY=-1
    username: sa
    password:
    driver-class-name: org.h2.Driver
  h2:
    console:
      enabled: true
      path: /h2-console
  jpa:
    database-platform: org.hibernate.dialect.H2Dialect
    show-sql: true
    hibernate:
      ddl-auto: update

#  kafka:
#    bootstrap-servers: localhost:9092
#    consumer:
#      group-id: kafka-data-group
#      auto-offset-reset: earliest
#    template:
#      default-topic: kafka-data-topic


csv:
  input:
    directory: D:\\BJB\\ROC_BJB\\fileProcessor\\data\\input
  processed:
    directory: D:\\BJB\\ROC_BJB\\fileProcessor\\data\\processed
  error:
    directory: D:\\BJB\\ROC_BJB\\fileProcessor\\data\\error

batch:
  size: 100

parallel:
  threads: 10
  maxThreads: 20


logging:
  level:
    root: INFO
    com.camel: DEBUG
    org.apache.camel: INFO
    org.hibernate.SQL: DEBUG
    org.hibernate.type.descriptor.sql: TRACE
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/file-processor.log
  logback:
    rollingpolicy:
      max-history: 30
      max-file-size: 20MB


camel:
  springboot:
    main-run-controller: true
  main:
   name: FileProcessor
  dataformat:
   csv:
    skip-header-record: true
    use-maps: true
  management:
    enable: true

kafka:
  bootstrap:
    servers: localhost:9092
  topic: my-kafka-topic
  group-id: kafka-consumer-group
  auto:
    offset:
      reset: earliest
